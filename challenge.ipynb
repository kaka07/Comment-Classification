{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.core.display import display, HTML\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for ploting history of the model training\n",
    "from pyspark.sql import Row\n",
    "def plot_history(history_arg):\n",
    "  array = []\n",
    "  i =1\n",
    "  j =1\n",
    "  for acc in history_arg.history['acc']:\n",
    "    array.append(Row(epoch=i, accuracy=float(acc)))\n",
    "    i = i+1\n",
    "  acc_df = sqlContext.createDataFrame((array))\n",
    "\n",
    "  array = []\n",
    "  for loss in history_arg.history['loss']:\n",
    "      array.append(Row(epoch = j, loss = float(loss)))\n",
    "      j = j+1\n",
    "  loss_df = sqlContext.createDataFrame(array)\n",
    "\n",
    "  display_df = acc_df.join(loss_df,on=(\"epoch\")).orderBy(\"epoch\")\n",
    "  return display_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "#Class labels\n",
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "\n",
    "#Read the data\n",
    "toxicWordsTrain = pd.read_csv(\"train.csv\");\n",
    "toxicWordsTest = pd.read_csv(\"test.csv\")\n",
    "\n",
    "y_train = toxicWordsTrain[list_classes].values\n",
    "x_train = toxicWordsTrain[\"comment_text\"]\n",
    "x_test  = toxicWordsTest[\"comment_text\"]\n",
    "\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAAGECAYAAAAyfvofAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de7xVdZ3/8dcHyMwbSIJxEVFBJxRFPaNm5TDieEtBSyfp4gXTxlFT85LNjGk5TlkW5U9ztLK0HNE0E01TwijzhqAUXkdUJlATUTSKvACf3x9rnePmcEAO7nP2OcvX8/HYj732d33X2t+1zj5rv/da37VWZCaSJElV1qPRDZAkSepoBh5JklR5Bh5JklR5Bh5JklR5Bh5JklR5Bh5JklR5Bh5J3V5EnBMRP2l0OyR1XQYeSd1GRHwiImZExF8i4rmIuDUiPtTodknq+no1ugGStCYi4vPAmcC/ALcBrwP7AuOAvzawaZK6AffwSOryIqI38BXg+Mz8WWb+NTPfyMybMvP0Nur/NCL+FBGvRMRvI2LbmnH7R8QjEbE4Ip6JiNPK8k0i4uaIeDkiXoqIOyPCbaRUEf4zS+oOPgCsC9ywhvVvBYYD/YEHgKtqxv0A+GxmbghsB9xRlp8KzAf6AZsC/wZ47x2pIjykJak7eC+wMDOXrknlzLy8eTgizgEWRUTvzHwFeAMYERG/z8xFwKKy6hvAAGDzzJwD3FnPBZDUWO7hkdQdvAhsEhFv+SMtInpGxNci4smI+DMwtxy1Sfn8MWB/4P8i4jcR8YGy/BvAHOD2iHgqIs6s7yJIaiQDj6Tu4B7gVeCgNaj7CYqOzHsBvYGhZXkAZOb9mTmO4nDXz4Fry/LFmXlqZm4JHAh8PiLG1HMhJDWOgUdSl1ceivoScHFEHBQR60XEuyJiv4j4eqvqGwKvUewVWg/4r+YREbFORHyyPLz1BvBnYFk57oCIGBYRUVO+rOOXTlJnMPBI6hYy81vA54H/AF4A5gEnUOylqXUl8H/AM8AjwL2txn8amFse7voX4FNl+XDgV8BfKPYofTczp9V9QSQ1RGR6EoIkSao29/BIkqTKM/BIkqTK65TAExGXR8SCiHioVfmJEfF4RDxc2/EwIr4YEXPKcfvUlO9bls2pPWU0IraIiPsi4omIuCYi1umM5ZIkSd1DZ+3h+RHFPW9aRMQ/Upw6un1mbgtcUJaPAA4Dti2n+W55XY2ewMXAfsAIYHxZF+B8YGJmDqe4iNjRHb5EkiSp2+iUwJOZvwVealV8HPC1zHytrLOgLB8HTMrM1zLzaYoLge1SPuZk5lOZ+TowCRhXnkK6J3BdOf0VrNm1OiRJ0jtEI28tsTXw4Yg4j+KCYqdl5v3AIFY8jXR+WQbFaai15btSXHL+5ZpLztfWX61NNtkkhw4dutYLIEmSuo6ZM2cuzMx+bY1rZODpBWwM7Ab8PXBtRGxJeTXUVpK290blauq3KSKOBY4FGDJkCDNmzGhnsyVJUlcUEf+3qnGNPEtrPvCzLEwHllPc62Y+sFlNvcHAs6spXwj0qbnHTnN5mzLzssxsysymfv3aDIGSJKliGhl4fk7R94aI2BpYhyK8TAYOi4h3R8QWFFc/nQ7cDwwvz8hah6Jj8+Qsrpz4a+CQcr5HADd26pJIkqQurVMOaUXE1cBoirsdzwfOBi4HLi9PVX8dOKIMLw9HxLUUl4RfChyfmc33ujkBuA3oCVyemQ+Xb/EFYFJE/CfwIPCDzlguSZLUPbyjby3R1NSU9uGRJKkaImJmZja1Nc4rLXeSCRMm0L9/f7bbbruWsnPOOYdBgwYxatQoRo0axS233ALAlClT2HnnnRk5ciQ777wzd9xxR8s011xzDdtvvz3bbrstZ5xxxkrvc9111xERdsaWJKmGgaeTHHnkkfzyl79cqfyUU05h1qxZzJo1i/333x+ATTbZhJtuuonZs2dzxRVX8OlPfxqAF198kdNPP52pU6fy8MMP8/zzzzN16tSWeS1evJgLL7yQXXfdtXMWSpKkbsLA00n22GMP+vbtu0Z1d9xxRwYOHAjAtttuy6uvvsprr73GU089xdZbb03z2WV77bUX119/fct0Z511FmeccQbrrrtu/RdAkqRuzMDTYBdddBHbb789EyZMYNGiRSuNv/7669lxxx1597vfzbBhw3jssceYO3cuS5cu5ec//znz5hXXYnzwwQeZN28eBxxwQGcvgiRJXZ6Bp4GOO+44nnzySWbNmsWAAQM49dRTVxj/8MMP84UvfIFLL70UgI033phLLrmEj3/843z4wx9m6NCh9OrVi+XLl3PKKafwzW9+sxGLIUlSl2fgaaBNN92Unj170qNHD4455himT5/eMm7+/PkcfPDBXHnllWy11VYt5QceeCD33Xcf99xzD9tssw3Dhw9n8eLFPPTQQ4wePZqhQ4dy7733MnbsWDsuS5JUMvA00HPPPdcyfMMNN7ScwfXyyy/zkY98hK9+9at88IMfXGGaBQuKe6wuWrSI7373u3zmM5+hd+/eLFy4kLlz5zJ37lx22203Jk+eTFNTm2fmSZL0jtPIe2m9o4wfP55p06axcOFCBg8ezJe//GWmTZvGrFmziAiGDh3acujqoosuYs6cOZx77rmce+65ANx+++3079+fk046id///vcAfOlLX2Lrrbdu2DJJktRdeOFBD/tIklQJq7vwoHt4VuOICZs2ugldxhWXP9/oJkiStNbswyNJkirPwCNJkirPwCNJkirPwCNJkirPwCNJkirPwCNJkirPwCNJkirPwCNJkirPwCNJkirPwCNJkirPwCNJkirPwCNJkirPwCNJkirPwCNJkirPwCNJkirPwCNJkirPwCNJkirPwCNJkirPwCNJkirPwCNJkirPwCNJkirPwCNJkiqvUwJPRFweEQsi4qE2xp0WERkRm5SvIyIujIg5EfGHiNippu4REfFE+TiipnzniJhdTnNhRERnLJckSeoeOmsPz4+AfVsXRsRmwD8Bf6wp3g8YXj6OBS4p6/YFzgZ2BXYBzo6IjctpLinrNk+30ntJkqR3rk4JPJn5W+ClNkZNBM4AsqZsHHBlFu4F+kTEAGAfYEpmvpSZi4ApwL7luI0y857MTOBK4KCOXB5JktS9NKwPT0SMBZ7JzN+3GjUImFfzen5Ztrry+W2US5IkAdCrEW8aEesB/w7s3dboNspyLcpX9d7HUhz+YsiQIW/ZVkmS1P01ag/PVsAWwO8jYi4wGHggIt5HsYdms5q6g4Fn36J8cBvlbcrMyzKzKTOb+vXrV4dFkSRJXV1DAk9mzs7M/pk5NDOHUoSWnTLzT8Bk4PDybK3dgFcy8zngNmDviNi47Ky8N3BbOW5xROxWnp11OHBjI5ZLkiR1TZ11WvrVwD3ANhExPyKOXk31W4CngDnA94B/BcjMl4BzgfvLx1fKMoDjgO+X0zwJ3NoRyyFJkrqnTunDk5nj32L80JrhBI5fRb3LgcvbKJ8BbPf2WilJkqrKKy1LkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTKM/BIkqTK65TAExGXR8SCiHiopuwbEfFYRPwhIm6IiD41474YEXMi4vGI2KemfN+ybE5EnFlTvkVE3BcRT0TENRGxTmcslyRJ6h46aw/Pj4B9W5VNAbbLzO2B/wW+CBARI4DDgG3Lab4bET0joidwMbAfMAIYX9YFOB+YmJnDgUXA0R27OJIkqTvplMCTmb8FXmpVdntmLi1f3gsMLofHAZMy87XMfBqYA+xSPuZk5lOZ+TowCRgXEQHsCVxXTn8FcFCHLpAkSepWukofngnAreXwIGBezbj5Zdmqyt8LvFwTnprL2xQRx0bEjIiY8cILL9Sp+ZIkqStreOCJiH8HlgJXNRe1US3XorxNmXlZZjZlZlO/fv3a21xJktQN9Wrkm0fEEcABwJjMbA4p84HNaqoNBp4th9sqXwj0iYhe5V6e2vqSJEmN28MTEfsCXwDGZuaSmlGTgcMi4t0RsQUwHJgO3A8ML8/IWoeiY/PkMij9GjiknP4I4MbOWg5JktT1ddZp6VcD9wDbRMT8iDgauAjYEJgSEbMi4r8BMvNh4FrgEeCXwPGZuazce3MCcBvwKHBtWReK4PT5iJhD0afnB52xXJIkqXvolENamTm+jeJVhpLMPA84r43yW4Bb2ih/iuIsLkmSpJU0vNOyJElSRzPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyjPwSJKkyuuUwBMRl0fEgoh4qKasb0RMiYgnyueNy/KIiAsjYk5E/CEidqqZ5oiy/hMRcURN+c4RMbuc5sKIiM5YLkmS1D101h6eHwH7tio7E5iamcOBqeVrgP2A4eXjWOASKAIScDawK7ALcHZzSCrrHFszXev3kiRJ72CdEngy87fAS62KxwFXlMNXAAfVlF+ZhXuBPhExANgHmJKZL2XmImAKsG85bqPMvCczE7iyZl6SJEkN7cOzaWY+B1A+9y/LBwHzaurNL8tWVz6/jXJJkiSga3Zabqv/Ta5Fedszjzg2ImZExIwXXnhhLZsoSZK6k0YGnufLw1GUzwvK8vnAZjX1BgPPvkX54DbK25SZl2VmU2Y29evX720vhCRJ6voaGXgmA81nWh0B3FhTfnh5ttZuwCvlIa/bgL0jYuOys/LewG3luMURsVt5dtbhNfOSJEmiV2e8SURcDYwGNomI+RRnW30NuDYijgb+CBxaVr8F2B+YAywBjgLIzJci4lzg/rLeVzKzuSP0cRRngr0HuLV8SJIkAZ0UeDJz/CpGjWmjbgLHr2I+lwOXt1E+A9ju7bRRkiRV1xoHnogYAbyYmc9HxAbA6cAy4ILMXNJRDZQkSXq72tOH53+APuXwBcAewAeAS+vdKEmSpHpqzyGtoZn5eNkx+GBgW+BvwNMd0jJJkqQ6aU/geS0iNgRGAPMyc2FE9ALW7ZimSZIk1Ud7As//AHcAGwIXlWU74R4eSZLUxa1x4MnMUyJib+CNzPx1WbwcOKVDWiZJklQn7TotPTNvj4jNImK3zLy3PB1ckiSpS1vjs7QiYkhE3AU8BvyqLDskIr7fUY2TJEmqh/acln4p8AuKPjxvlGVTgH+qd6MkSZLqqT2HtHYBPpKZyyMiATLzlYjo3TFNkyRJqo/27OF5HhhWW1BeffmPdW2RJElSnbUn8FwA3BwRRwG9ImI8cA1wfoe0TJIkqU7ac1r65RHxEnAsMA84HDgrM3/eUY2TJEmqh/aelv5zwIAjSZK6lfacln5hROzeqmz3iPh2/ZslSZJUP+3pwzMeaH2hwZnAJ+rXHEmSpPprT+DJNur3bOc8JEmSOl17wsqdwH9GRA+A8vmcslxSRUycOJFtt92W7bbbjvHjx/Pqq6+2jDvxxBPZYIMNVprmuuuuIyKYMaPYCfz6669z1FFHMXLkSHbYYQemTZvWWc2XpDa1J/CcBOwFPBcR04FnKa6yfGJHNExS53vmmWe48MILmTFjBg899BDLli1j0qRJAMyYMYOXX355pWkWL17MhRdeyK677tpS9r3vfQ+A2bNnM2XKFE499VSWL1/eOQshSW1Y48CTmfOBnYCDgG+UzzuX5ZIqYunSpfztb39j6dKlLFmyhIEDB7Js2TJOP/10vv71r69U/6yzzuKMM85g3XXXbSl75JFHGDNmDAD9+/enT58+LXt/JKkR2tX/JjOXZ+Y9wPXAdGg5tCWpAgYNGsRpp53GkCFDGDBgAL1792bvvffmoosuYuzYsQwYMGCF+g8++CDz5s3jgAMOWKF8hx124MYbb2Tp0qU8/fTTzJw5k3nz5nXmokjSCtb4OjwRsRNwMbA90PxTLig6M/esf9MkdbZFixZx44038vTTT9OnTx8OPfRQrrzySn7605+u1A9n+fLlnHLKKfzoRz9aaT4TJkzg0Ucfpampic0335zdd9+dXr3addkvSaqr9myBrgBuAiYASzqmOZIa6Ve/+hVbbLEF/fr1A+CjH/0oZ599Nn/7298YNqy4ld6SJUsYNmwYM2fO5KGHHmL06NEA/OlPf2Ls2LFMnjyZpqYmJk6c2DLf3XffneHDh3f68khSs/YEns2Bf8/M7KjGSGqsIUOGcO+997JkyRLe8573MHXqVD7/+c9z4olvnpuwwQYbMGfOHAAWLlzYUj569GguuOACmpqaWLJkCZnJ+uuvz5QpU+jVqxcjRozo9OWRpGbtCTw3AHsDt3VQWyQ12K677sohhxzCTjvtRK9evdhxxx059thj2z2fBQsWsM8++9CjRw8GDRrEj3/84w5orSStuVjTHTYRcQ1wIPA74E+14zLz8Po3reM1NTXl6s4cOWLCpp3Ymq7tisufb3QTJElarYiYmZlNbY1rzx6eR8qHpAa7dNx3G92ELuOzN/5ro5sgqRtY48CTmV/uyIZIkiR1lHZdQyci/ikifhARN5WvmyJiz45pmiRJhccff5xRo0a1PDbaaCO+/e1vM2vWLHbbbTdGjRpFU1MT06dPB+Ab3/hGS93tttuOnj178tJLL61yPqq+9lyH50SK20t8HzikLP4bcCGwe/2bJklSYZtttmHWrFkALFu2jEGDBnHwwQdzzDHHcPbZZ7Pffvtxyy23cMYZZzBt2jROP/10Tj/9dABuuukmJk6cSN++fenbt2+b81H1tWcPz8nAXpn5NaD5pjiPAdvUvVWSJK3C1KlT2Wqrrdh8882JCP785z8D8MorrzBw4MCV6l999dWMHz9+tfNR9bWn0/KGQPO14ZtP7XoX8HpdWyRJ0mpMmjSpJcB8+9vfZp999uG0005j+fLl3H333SvUXbJkCb/85S+56KKLVjsfVV979vD8FjizVdnngF+/nQZExCkR8XBEPBQRV0fEuhGxRUTcFxFPRMQ1EbFOWffd5es55fihNfP5Yln+eETs83baJEnqml5//XUmT57MoYceCsAll1zCxIkTmTdvHhMnTuToo49eof5NN93EBz/4Qfr27bva+aj62hN4TgQOjoi5wIYR8ThwKPD5tX3ziBhEEZqaMnM7intyHQacD0zMzOHAIqD5E3w0sCgzhwETy3pExIhyum2BfYHvRoT395Kkirn11lvZaaed2HTT4jppV1xxBR/96EcBOPTQQ1s6LTdb1V6c1vNR9bUn8DwP/D3wz8AngCOAXTPzT6ud6q31At4TEb2A9YDngD2B68rxVwAHlcPjyteU48dERJTlkzLztcx8GpgD7PI22yVJ6mJa98cZOHAgv/nNbwC44447Vrhn2yuvvMJvfvMbxo0b95bzUfWtUR+ecm/JX4A+mTkdmP4Wk6yRzHwmIi4A/khxxtftwEzg5cxcWlabDwwqhwdR9iPKzKUR8Qrw3rL83ppZ107TelmOBY6F4r5BkqTuYcmSJUyZMoVLL720pex73/seJ510EkuXLmXdddflsssuaxl3ww03sPfee7P++uu/5XxUfWsUeDJzWUT8L0W4eLZebx4RG1PsndkCeBn4KbBfW01onmQV41ZVvnJh5mXAZVDcWqKdTZYkNch6663Hiy++uELZhz70IWbOnNlm/SOPPJIjjzxyjeaj6mvPWVpXATdHxHco9qC0hIXMvGMt338v4OnMfAEgIn5GcU2fPhHRq9zLM5g3Q9Z8YDNgfnkIrDfwUk15s9ppJEnSO1x7As9x5fM5rcoT2HIt3/+PwG4RsR7FIa0xwAyKM78OASZR9BW6saw/uXx9Tzn+jszMiJgM/E9EfAsYCAynTofdJEnt896Nj210E7qMFxdd9taV1CnaE3iGZeayer55Zt4XEdcBDwBLgQcpDjf9ApgUEf9Zlv2gnOQHwI8jYg7Fnp3Dyvk8HBHXUtzcdClwfL3bKkmSuq92dVqOiD6Z+Vo9G5CZZwNntyp+ijbOssrMVylOhW9rPucB59WzbZIkqRrW6LT0cm9Jc6dlSZKkbqXRnZYlSZI6XKM7LUuSJHW4NQ48mblFRzZEkiSpo7Tn1hKSJEnd0hrv4YmIeaz66sXeo0GSJHVZ7enD86lWrwcAJ1FcHFCSJKnLak8fnt+0LouIacAvge/UsU2SJEl19Xb78LxGceNPSZKkLqs9fXi+0qpoPWB/4Na6tkiSJKnO2tOHZ7NWr/8KfAv4cf2aI0mSVH/t6cNzVEc2RJIkqaOscR+eiDgzIv6+VdkuEXFG/ZslSZJUP+3ptHwS8EirskeAk+vXHEmSpPprT+BZB3ijVdnrwLr1a44kSVL9tSfwzAT+tVXZvwAP1K85kiRJ9dees7ROAaZExKeBJ4FhwKbAP3VEwyRJkuqlPWdpPRwRWwMHUJyi/jPg5sz8S0c1TpIkqR7ac+HBQcCSzJxUU7ZxRAzMzGc7pHWSJEl10J4+PD8HBrcqGwzcUL/mSJIk1V97As/WmTm7tqB8/Xf1bZIkSVJ9tSfwvBARw2oLytcv1rdJkiRJ9dWewHM5cH1EHBgRIyLiQOA64Psd0zRJkqT6aM9p6V+juNDgNyj67swDfkBxA1FJkqQua40CT0T0Aj4F7Aj8keJig78CfpyZyzuueZIkSW/fWx7SiojewN3A+RS3lphJsafnq8Dd5XhJkqQua0328HwVeAH4x8z8a3NhRKwPXFuOb33LCUmSpC5jTTotHwQcVxt2AMrXxwMHd0TDJEmS6mVNAk9v4JlVjJsPbFS/5kiSJNXfmgSeJ4E9VzFuDPBU/ZojSZJUf2sSeL4FXBkRH4uIHgAR0SMiDgF+hKelS5KkLu4tA09m/gi4gCLcvBoRzwKvAj8EvpWZP3w7DYiIPhFxXUQ8FhGPRsQHIqJvREyJiCfK543LuhERF0bEnIj4Q0TsVDOfI8r6T0TEEW+nTZIkqVrW6ErLmflNYCBwIHB6+TwoM79RhzZ8B/hlZv4dsAPwKHAmMDUzhwNTy9cA+wHDy8exwCUAEdEXOBvYFdgFOLs5JEmSJK3xlZYzczFwWz3fPCI2AvYAjizf43Xg9YgYB4wuq10BTAO+AIwDrszMBO4t9w4NKOtOycyXyvlOAfYFrq5neyVJUvfUnntpdYQtKa7x88OIeDAivl9e32fTzHwOoHzuX9YfRHFLi2bzy7JVlUuSJDU88PQCdgIuycwdgb/y5uGrtkQbZbma8pVnEHFsRMyIiBkvvPBCe9srSZK6oUYHnvnA/My8r3x9HUUAer48VEX5vKCm/mY10w8Gnl1N+Uoy87LMbMrMpn79+tVtQSRJUtfV0MCTmX8C5kXENmXRGOARYDLQfKbVEcCN5fBk4PDybK3dgFfKQ163AXtHxMZlZ+W9qXN/I0mS1H2tcaflDnQicFVErENxEcOjKILYtRFxNMXd2Q8t694C7A/MAZaUdcnMlyLiXOD+st5XmjswS5IkNTzwZOYsoKmNUWPaqJsU9+9qaz6XA5fXt3WSJKkKGt2HR5IkqcMZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuV1icATET0j4sGIuLl8vUVE3BcRT0TENRGxTln+7vL1nHL80Jp5fLEsfzwi9mnMkkiSpK6oSwQe4CTg0ZrX5wMTM3M4sAg4uiw/GliUmcOAiWU9ImIEcBiwLbAv8N2I6NlJbZckSV1cwwNPRAwGPgJ8v3wdwJ7AdWWVK4CDyuFx5WvK8WPK+uOASZn5WmY+DcwBdumcJZAkSV1dwwMP8G3gDGB5+fq9wMuZubR8PR8YVA4PAuYBlONfKeu3lLcxjSRJeodraOCJiAOABZk5s7a4jar5FuNWN03r9zw2ImZExIwXXnihXe2VJEndU6P38HwQGBsRc4FJFIeyvg30iYheZZ3BwLPl8HxgM4ByfG/gpdryNqZZQWZelplNmdnUr1+/+i6NJEnqkhoaeDLzi5k5ODOHUnQ6viMzPwn8GjikrHYEcGM5PLl8TTn+jszMsvyw8iyuLYDhwPROWgxJktTF9XrrKg3xBWBSRPwn8CDwg7L8B8CPI2IOxZ6dwwAy8+GIuBZ4BFgKHJ+Zyzq/2ZIkqSvqMoEnM6cB08rhp2jjLKvMfBU4dBXTnwec13EtlCRJ3VWj+/BIkiR1OAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqPAOPJEmqvIYGnojYLCJ+HRGPRsTDEXFSWd43IqZExBPl88ZleUTEhRExJyL+EBE71czriLL+ExFxRKOWSZIkdT2N3sOzFDg1M98P7AYcHxEjgDOBqZk5HJhavgbYDxhePo4FLoEiIAFnA7sCuwBnN4ckSZKkhgaezHwuMx8ohxcDjwKDgHHAFeh5rpgAABPJSURBVGW1K4CDyuFxwJVZuBfoExEDgH2AKZn5UmYuAqYA+3bioqiBJkyYQP/+/dluu+1ays455xwGDRrEqFGjGDVqFLfccgsAr7/+OkcddRQjR45khx12YNq0aS3TjB49mm222aZlmgULFnT2okiSOkivRjegWUQMBXYE7gM2zcznoAhFEdG/rDYImFcz2fyybFXlbb3PsRR7hxgyZEj9FkANc+SRR3LCCSdw+OGHr1B+yimncNppp61Q9r3vfQ+A2bNns2DBAvbbbz/uv/9+evQosv9VV11FU1NT5zRcktRpGn1IC4CI2AC4Hjg5M/+8uqptlOVqylcuzLwsM5sys6lfv37tb6y6nD322IO+ffuuUd1HHnmEMWPGANC/f3/69OnDjBkzOrJ5kqQuoOGBJyLeRRF2rsrMn5XFz5eHqiifm48tzAc2q5l8MPDsasr1DnbRRRex/fbbM2HCBBYtWgTADjvswI033sjSpUt5+umnmTlzJvPmvblz8KijjmLUqFGce+65ZLaZmSVJ3VCjz9IK4AfAo5n5rZpRk4HmM62OAG6sKT+8PFtrN+CV8tDXbcDeEbFx2Vl577JM71DHHXccTz75JLNmzWLAgAGceuqpQNHfZ/DgwTQ1NXHyySez++6706tXcWT3qquuYvbs2dx5553ceeed/PjHP27kIkhSh2qr/2OzCy64gIhg4cKFAGQmn/vc5xg2bBjbb789DzzwQEvdnj17tvR9HDt2bKe1v70a3Yfng8CngdkRMass+zfga8C1EXE08Efg0HLcLcD+wBxgCXAUQGa+FBHnAveX9b6SmS91ziKoK9p0001bho855hgOOOAAAHr16sXEiRNbxu2+++4MHz4cgEGDim5fG264IZ/4xCeYPn36Sv2CJKkqVtX/cd68eUyZMmWFfq633norTzzxBE888QT33Xcfxx13HPfddx8A73nPe5g1axZdXUMDT2b+jrb73wCMaaN+AsevYl6XA5fXr3Xqzp577jkGDBgAwA033NDyC2bJkiVkJuuvvz5TpkyhV69ejBgxgqVLl/Lyyy+zySab8MYbb3DzzTez1157NXIRJKlD7bHHHsydO3el8lNOOYWvf/3rjBs3rqXsxhtv5PDDDyci2G233Xj55ZdX2M52B43ewyO9bePHj2fatGksXLiQwYMH8+Uvf5lp06Yxa9YsIoKhQ4dy6aWXArBgwQL22WcfevTowaBBg1oOW7322mvss88+vPHGGyxbtoy99tqLY445ppGLJUmdbvLkyQwaNIgddthhhfJnnnmGzTZ7s6vs4MGDeeaZZxgwYACvvvoqTU1N9OrVizPPPJODDjqo9Wy7BAOPur2rr756pbKjjz66zbpDhw7l8ccfX6l8/fXXZ+bMmXVvmyR1F0uWLOG8887j9ttvX2lcWydxFN1w4Y9//CMDBw7kqaeeYs8992TkyJFstdVWHd7e9jLwqNO89x+3bHQTuowXf/1Uo5sgSSt48sknefrpp1v27syfP5+ddtqJ6dOnM3jw4BXOaJ0/fz4DBw4EaHnecsstGT16NA8++GCXDDwNPy1dkiQ13siRI1mwYAFz585l7ty5DB48mAceeID3ve99jB07liuvvJLM5N5776V3794MGDCARYsW8dprrwGwcOFC7rrrLkaMGNHgJWmbe3gkSXoHaqv/46q6A+y///7ccsstDBs2jPXWW48f/vCHADz66KN89rOfpUePHixfvpwzzzzTwCNJkrqOtvo/1qo9gysiuPjii1eqs/vuuzN79ux6N61DGHgkSerCxu+6UaOb0GVcfd/q7j61evbhkSRJlWfgkSRJlWfgkSRJlWfgkSRJlWfgkSRJlWfgkSRJlWfgkSRJlWfgkSRJlWfgkaROtGzZMnbccUcOOOAAAD784Q8zatQoRo0axcCBAznooIMAeOWVVzjwwAPZYYcd2HbbbVsu5S9p7XilZUnqRN/5znd4//vfz5//XFwx9s4772wZ97GPfYxx48YBcPHFFzNixAhuuukmXnjhBbbZZhs++clPss466zSk3VJ35x4eSeok8+fP5xe/+AWf+cxnVhq3ePFi7rjjjpY9PBHB4sWLyUz+8pe/0LdvX3r18jeqtLb875GkTnLyySfz9a9/ncWLF6807oYbbmDMmDFstFFx36QTTjiBsWPHMnDgQBYvXsw111xDjx7+RpXWlv89ktQJbr75Zvr378/OO+/c5virr76a8ePHt7y+7bbbGDVqFM8++yyzZs3ihBNOaDkMJqn9DDyS1AnuuusuJk+ezNChQznssMO44447+NSnPgXAiy++yPTp0/nIRz7SUv+HP/whH/3oR4kIhg0bxhZbbMFjjz3WqOZL3Z6BR5I6wVe/+lXmz5/P3LlzmTRpEnvuuSc/+clPAPjpT3/KAQccwLrrrttSf8iQIUydOhWA559/nscff5wtt9yyIW2XqsDAI0kNNmnSpBUOZwGcddZZ3H333YwcOZIxY8Zw/vnns8kmmzSohVL3Z6dlSepko0ePZvTo0S2vp02btlKdgQMHcvvtt3deo6SKcw+PJEmqPPfwSHrHO67Pxo1uQpdxycuLGt0EqUO4h0eSJFWegUeSJFWegUeSJFWegUeSJFWegUeSJFVepQJPROwbEY9HxJyIOLPR7ZEkSV1DZQJPRPQELgb2A0YA4yNiRGNbJUmSuoLKBB5gF2BOZj6Vma8Dk4BxDW6TJEnqAqoUeAYB82pezy/LJEnSO1xkZqPbUBcRcSiwT2Z+pnz9aWCXzDyxVb1jgWPLl9sAj3dqQ9fOJsDCRjeiIlyX9eX6rC/XZ/24Luuru6zPzTOzX1sjqnRrifnAZjWvBwPPtq6UmZcBl3VWo+ohImZkZlOj21EFrsv6cn3Wl+uzflyX9VWF9VmlQ1r3A8MjYouIWAc4DJjc4DZJkqQuoDJ7eDJzaUScANwG9AQuz8yHG9wsSZLUBVQm8ABk5i3ALY1uRwfoVofgujjXZX25PuvL9Vk/rsv66vbrszKdliVJklalSn14JEmS2mTgaYCI6BMR/7qW0zZFxIX1bpPeuSJiaEQ81Oh2VEXt/3dEjI6ImzvofUZHxO4dMe+uKCLurvP8Wj73ETEqIvav5/zV9Rh4GqMPsFaBJzNnZObn6twe8fa/QCLiKxGxVz3bpG6p3f/f5a1x2ms08I4JPJnZkcs6CujSgWdVgS8ifhQRh6zlPFcIehExtvk+lBFx0Nreniki5kbEJmvbjo5i4GmMrwFbRcSsiPhG+XgoImZHxMcBIuLgiPhVFAZExP9GxPtqfzFGxAYR8cNyuj9ExMcaulRdTES0t1P+aN7GF0hmfikzf7W203eWiPh8+Xl7KCJOLot7RcQV5efouohYr6z7tYh4pCy/oCzbNCJuiIjfl4/dy/JPRcT08nN9afOXeET8JSLOK+veGxGbluX9IuL6iLi/fHywAaujI7T8fwPfADYo1+ljEXFVRAS0fCl8KSJ+BxwaEVtFxC8jYmZE3BkRf1fWOzAi7ouIB8ttwqYRMRT4F+CUcn1/uDGL2nki4i/l8+iImLaKddrW53WFQNA8n5rX6wBfAT5ersuPd95SrbkOCnwrBL3MnJyZXytfHkRxX8rO0DmBMzN9dPIDGAo8VA5/DJhCcSr9psAfgQHluJ8AJwA3A+PLstHAzeXw+cC3a+a7caOXbQ2Xf33gF8DvgYeAjwM7A78BZlJcWmAA8H5geqv19odyeKX6Zfk04L/KcacC/YDrKa7TdD/wwdX8Tf4EPAPMAj4MbA5MBf5QPg8p694IHF4Ofxa4qhz+EXBIOfz3wN3lMk4HNmz0eq9Zb7PLv8EGwMPAjkA2rxvgcuA0oC/FlcibT27oUz5fA5xcDvcEepd/q5uAd5Xl361ZRwkcWA5/HfiPcvh/gA+Vw0OARxu9fuq0jmv/v0cDr1BcCLUHcE/NMs8FzqiZbiowvBzeFbijHN645m/wGeCb5fA5wGmNXt5OXK9/Wd06Xc3nteX/stV8av9ORwIXNXoZ13D5A7gIeIRiO3pLzXZnddvF88tt0f9SbN/Wofi+eYFim/fx5vVA8cPvJeDpctxWwAM1bRkOzFxNW+cCXwYeoNje/F1ZvgvFdvHB8nmbVbRjfYrt0P1l3XH1WIeVOi29m/oQcHVmLgOej4jfUHxZTgZOpAgE92bm1W1MuxfFBRYByMxFndDeetgXeDYzPwIQEb2BWyk+1C+Uv7DOy8wJEbFORGyZmU9R/CNcGxHvAv5f6/rAhHL+fTLzH8p5/w8wMTN/FxFDKDYC72/doMycGxH/TbFRaf5leBNwZWZeERETgAspfvUcC9wVEU9ThKrdaudV/mK8Bvh4Zt4fERsBf6vTunu7PgTckJl/BYiIn1Fs/OZl5l1lnZ8AnwO+DbwKfD8ifkERvAH2BA4HKD+3r0RxK5edgfvLH9vvARaU9V+vmXYm8E/l8F7AiLI+wEYRsWFmLq7rEjfe9MycD1Du9RkK/K4cd01ZvgHFl8xPa9bHu8vnwcA1ETGA4svh6c5pdpfW1jq9l7Y/r1VzMEVQGEnxI/kR4PI12C72ysxdykNHZ2fmXhHxJaApM08AiIgjATLz7oiYTPHj+rpy3CsRMSozZwFHUQTJ1VmYmTtF0Z/tNIqw/hiwRxbXzdsL+K/M/Fgb7fgvisA/ISL6ANMj4lfN2621ZeBpvFjNuEHAcmDTiOiRmcvbmLY7XldgNnBBRJxPsVFaBGwHTCk39j2B58q61wL/THGY4OPlY5vV1IfyS6T0dr5UPwB8tBz+McXeCTLz+fIf9NfAwZn5UqvptgGey8z7y/p/XoP36iyr+ry1/hxluVHaBRhDEaxPoAg7q5rvFZn5xTbGvZHlzztgGW9ud3oAH8jMrhIGO8prNcO1yw/QvAHvAbycmaPamP7/Ad/KzMkRMZpiz8473UrrdDWf16WU3TfKQ1/rdHJb620P3vyR/GxE3FGWv9V28Wfl80yKgNhe3weOiojPU2yHd3mL+rXv17wd7Q1cERHDKbY571rFtHsDYyPitPL1upR7gdei3S3sw9MYi4ENy+HfUhw77hkR/Sg+zNOj6H/yQ+ATFH/kz7cxn9sp/qkBiIiNO7TVdZKZ/8ubh1a+SnFY7+HMHFU+Rmbm3mX1a4B/joiti0nzCYov11XVhze/RODNL9XmuoPexh6E2lAwEngRGNhGva4cRH8LHBQR60XE+hS/Fu8EhkTEB8o644HflXsdemdxQc+TKY6zQ3Ho5TgoOtuWe7CmAodERP+yvG9EbP4WbWn9+W3ry747qv3/XiNlKH46ipsgE4UdytG9KQ61Ahzxdt6nylbzeZ1Lsb0BGEfbX7LdbV22tX15q+1ic0hsHbrX1PXAfsABFIezXnyL+m2937nArzNzO+BAiiDTlgA+VrMsQzLzbYUdMPA0RPlBuSuKUyI/QNFH5PfAHRTH9P8E/BtwZ2beSRF2PhMRrQ/F/CewcRSdT38P/GOnLcTbEBEDgSWZ+RPgAor+Cv2av3Aj4l0RsS1AZj5J8Q9zFm/uuXl8VfXb0J4v1dYbvbt585DhJykPQ5S/Ivej6PtyWkRs0Wo+jwEDI+Lvy/obRvs7UHeIzHyAYlf0dOA+il9tiyhC9RER8QeKvhCXUKyLm8uy3wCnlLM5CfjHiJhN8ett28x8BPgP4Pay/hSKflir8zmgqexg+ghFJ9xur9X/9zfaMekngaPL/+WHKb6codij89OIuJMV71Z9E3BwvEM6La+BVX1evwf8Q0RMp9jWtHVY5NcUe4K7bKflGr8FDit/bAzgze1+e7aLzVYX9FYYl5mvUnQJuITix/jaqA3vR66mHbcBJ5Z75IiIHdfy/VZUj45APny05wHsQxHyZlF0Smui+DX2W4rg9zBwTE390yh+0QytKWuzPkXnvKaaeptQBKU/UBzr/u/VtGvrmnZ9mGK37x3UdFqm6Ffxe2CncpqxFBvLYOVOy/eWde8FNmj0evfhw0f3fdB2p+Wfl4/m7c5bbhfLbeLccrhvuQ1eodNyOe6D5Xs8CGxVlu1GEVh6vkVb5wKblMNNwLRy+AMUnabvotjbs6p2vAe4lOIowEOUJ+q83Ye3lpAkSW+p7FPTOzPPanRb1kaX2M0uSZK6roi4geL09FWduNDluYdH7zgRcRRFP5Rad2Xm8Y1ojyR1R2UIat2H8QuZeVsj2vNWDDySJKnyPEtLkiRVnoFHkiRVnp2WJXUbEfFeiksEALyP4hpNL5Svd8nM1xvSMEldnn14JHVLEXEONfc+k6TV8ZCWpG4vIr4aEcfXvD4/Iv41IvaKiF9HxM8j4pGIuLjm6q37RcQ9EfFARFxT3mpDUkUZeCRVwfcpL1UfET2BQ4Gry3G7UtxbaSTwfmBcec+vM4ExmbkTxdW0W1+qQFKF2IdHUreXmU9GxOKIGAlsDkzPzEXlzpx7M3MuQERMAj5UTjYCuLussw7lvdIkVZOBR1JV/IBiL89QivvwNGvdUTEp7kf0y8z8dKe0TFLDeUhLUlVcDxxIcQPFX9WU7xYRQ8pDXf9MsSfnboo7aG8JEBHrR8Twzm6wpM7jHh5JlZCZr0bEb4E/ZebymlF3A98EtqW4a/TkzMyIOBq4JiLWKev9G/BEZ7ZZUufxtHRJlRARPYBZwEGZ+VRZthdwQmYe1NDGSWo4D2lJ6vbKzspPUvTLearR7ZHU9biHR5IkVZ57eCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuUZeCRJUuX9fxvII1AHiFULAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 648x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "colors_list = [\"brownish green\", \"pine green\", \"ugly purple\",\n",
    "               \"blood\", \"deep blue\", \"brown\", \"azure\"]\n",
    "\n",
    "palette= sns.xkcd_palette(colors_list)\n",
    "\n",
    "x=toxicWordsTrain.iloc[:,2:].sum()\n",
    "#print(x.index)\n",
    "plt.figure(figsize=(9,6))\n",
    "ax= sns.barplot(x.index, x.values,palette=palette)\n",
    "plt.title(\"Class\")\n",
    "plt.ylabel('Occurrences', fontsize=12)\n",
    "plt.xlabel('Type ')\n",
    "rects = ax.patches\n",
    "labels = x.values\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 10, label, \n",
    "            ha='center', va='bottom')\n",
    "\n",
    "display(plt.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment #1:  Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "Label #1:    [0 0 0 0 0 0]\n",
      "Comment #2:  D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\n",
      "Label #2:    [0 0 0 0 0 0]\n",
      "Comment #3:  Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\n",
      "Label #3:    [0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Sample from dataset\n",
    "for sample_i in range(3):\n",
    "    print('Comment #{}:  {}'.format(sample_i + 1, x_train[sample_i]))\n",
    "    print('Label #{}:    {}'.format(sample_i + 1, y_train[sample_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 159571/159571 [00:04<00:00, 37548.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10734904 words.\n",
      "532299 unique words.\n",
      "10 Most common words in the dataset:\n",
      "\"the\" \"to\" \"of\" \"and\" \"a\" \"I\" \"is\" \"you\" \"that\" \"in\"\n"
     ]
    }
   ],
   "source": [
    "# Explore vocabulary\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create a counter object for each dataset\n",
    "word_counter = collections.Counter([word for sentence in tqdm(x_train, total=len(x_train)) \\\n",
    "                                                              for word in sentence.split()])\n",
    "\n",
    "print('{} words.'.format(len([word for sentence in x_train for word in sentence.split()])))\n",
    "print('{} unique words.'.format(len(word_counter)))\n",
    "print('10 Most common words in the dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*word_counter.most_common(10)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 210337\n",
      "Longest comment size: 1403\n",
      "Average comment size: 68.22156908210138\n",
      "Stdev of comment size: 101.07344657013672\n",
      "Max comment size: 371\n",
      "\n",
      "Sequence 1\n",
      "  Input:  Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "  Output: [688, 75, 1, 126, 130, 177, 29, 672, 4511, 12052, 1116, 86, 331, 51, 2278, 11448, 50, 6864, 15, 60, 2756, 148, 7, 2937, 34, 117, 1221, 15190, 2825, 4, 45, 59, 244, 1, 365, 31, 1, 38, 27, 143, 73, 3462, 89, 3085, 4583, 2273, 985]\n",
      "Sequence 2\n",
      "  Input:  D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\n",
      "  Output: [96145, 52, 2635, 13, 555, 3809, 73, 4556, 2706, 21, 94, 38, 803, 2679, 992, 589, 8377, 182]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and Pad\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Create tokenizer\n",
    "tokenizer = Tokenizer(num_words=None,\n",
    "                      filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                      lower=True,\n",
    "                      split=\" \",\n",
    "                      char_level=False)\n",
    "\n",
    "# Fit and run tokenizer\n",
    "tokenizer.fit_on_texts(list(x_train))\n",
    "tokenized_train = tokenizer.texts_to_sequences(x_train)\n",
    "tokenized_test = tokenizer.texts_to_sequences(x_test)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Extract variables\n",
    "vocab_size = len(word_index)\n",
    "print('Vocab size: {}'.format(vocab_size))\n",
    "longest = max(len(seq) for seq in tokenized_train)\n",
    "print(\"Longest comment size: {}\".format(longest))\n",
    "average = np.mean([len(seq) for seq in tokenized_train])\n",
    "print(\"Average comment size: {}\".format(average))\n",
    "stdev = np.std([len(seq) for seq in tokenized_train])\n",
    "print(\"Stdev of comment size: {}\".format(stdev))\n",
    "max_len = int(average + stdev * 3)\n",
    "print('Max comment size: {}'.format(max_len))\n",
    "print()\n",
    "\n",
    "# Pad sequences\n",
    "processed_X_train = pad_sequences(tokenized_train, maxlen=max_len, padding='post', truncating='post')\n",
    "processed_X_test = pad_sequences(tokenized_test, maxlen=max_len, padding='post', truncating='post')\n",
    "\n",
    "# Sample tokenization\n",
    "for sample_i, (sent, token_sent) in enumerate(zip(x_train[:2], tokenized_train[:2])):\n",
    "    print('Sequence {}'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(sent))\n",
    "    print('  Output: {}'.format(token_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "with h5py.File('embeddings.h5', 'w') as hf:\n",
    "    hf.create_dataset(\"fasttext\",  data=embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load embeddings\n",
    "with h5py.File('embeddings.h5', 'r') as hf:\n",
    "    embedding_matrix = hf['fasttext'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0422 01:28:34.897876 19856 deprecation_wrapper.py:119] From c:\\users\\hp\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0422 01:28:35.408354 19856 deprecation_wrapper.py:119] From c:\\users\\hp\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0422 01:28:35.514019 19856 deprecation_wrapper.py:119] From c:\\users\\hp\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0422 01:28:35.689703 19856 deprecation_wrapper.py:119] From c:\\users\\hp\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0422 01:28:35.692691 19856 deprecation_wrapper.py:119] From c:\\users\\hp\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0422 01:28:39.261752 19856 deprecation_wrapper.py:119] From c:\\users\\hp\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0422 01:28:39.776971 19856 deprecation.py:506] From c:\\users\\hp\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 371, 300)          63101400  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 371, 128)          192128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 123, 128)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 306       \n",
      "=================================================================\n",
      "Total params: 63,300,796\n",
      "Trainable params: 63,300,540\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras.backend\n",
    "from keras.models import Sequential\n",
    "from keras.layers import CuDNNGRU, Dense, Conv1D, MaxPooling1D\n",
    "from keras.layers import Dropout, GlobalMaxPooling1D, BatchNormalization\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "# Initate model\n",
    "model = Sequential()\n",
    "\n",
    "# Add Embedding layer\n",
    "model.add(Embedding(vocab_size + 1, embedding_dim, weights=[embedding_matrix], input_length=max_len, trainable=True))\n",
    "\n",
    "# Add Recurrent layers\n",
    "#model.add(Bidirectional(CuDNNGRU(300, return_sequences=True)))\n",
    "\n",
    "# Add Convolutional layer\n",
    "model.add(Conv1D(filters=128, kernel_size=5, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add fully connected layers\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(6, activation='sigmoid'))\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0422 01:29:32.684418 19856 deprecation_wrapper.py:119] From c:\\users\\hp\\python\\python37\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0422 01:29:32.702371 19856 deprecation.py:323] From c:\\users\\hp\\python\\python37\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "def loss(y_true, y_pred):\n",
    "     return keras.backend.binary_crossentropy(y_true, y_pred)\n",
    "\n",
    "lr = .0001\n",
    "model.compile(loss=loss, optimizer=Nadam(lr=lr, clipnorm=1.0),\n",
    "              metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import Callback\n",
    "\n",
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, filepath, validation_data=(), interval=1, max_epoch = 100):\n",
    "        super(Callback, self).__init__()\n",
    "        # Initialize state variables\n",
    "        self.interval = interval\n",
    "        self.filepath = filepath\n",
    "        self.stopped_epoch = max_epoch\n",
    "        self.best = 0\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        self.y_pred = np.zeros(self.y_val.shape)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict_proba(self.X_val, verbose=0)\n",
    "            current = roc_auc_score(self.y_val, y_pred)\n",
    "            logs['roc_auc_val'] = current\n",
    "\n",
    "            if current > self.best: #save model\n",
    "                print(\" - AUC - improved from {:.5f} to {:.5f}\".format(self.best, current))\n",
    "                self.best = current\n",
    "                self.y_pred = y_pred\n",
    "                self.stopped_epoch = epoch+1\n",
    "                self.model.save(self.filepath, overwrite=True)\n",
    "            else:\n",
    "                print(\" - AUC - did not improve\")\n",
    "            \n",
    "[X, X_val, y, y_val] = train_test_split(processed_X_train, y_train, test_size=0.03, shuffle=False)\n",
    "RocAuc = RocAucEvaluation(filepath='model.best.hdf5',validation_data=(X_val, y_val), interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 154783 samples, validate on 4788 samples\n",
      "Epoch 1/2\n",
      " 15744/154783 [==>...........................] - ETA: 1:16:47 - loss: 0.6396"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-7856dd5dc6ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m graph = model.fit(X, y, batch_size=batch_size, epochs=epochs,\n\u001b[0;32m     14\u001b[0m                   \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mRocAuc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                   verbose=1, shuffle=False)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\hp\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\hp\\python\\python37\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\python\\python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "\n",
    "# Set variables\n",
    "batch_size = 64\n",
    "epochs = 2\n",
    "\n",
    "# Set early stopping\n",
    "early_stop = EarlyStopping(monitor=\"roc_auc_val\", mode=\"max\", patience=2)\n",
    "                                                    \n",
    "# Train\n",
    "graph = model.fit(X, y, batch_size=batch_size, epochs=epochs,\n",
    "                  validation_data=(X_val, y_val), callbacks=[RocAuc, early_stop],\n",
    "                  verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
